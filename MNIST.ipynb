{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fetch/load data\n",
    "(X, Y), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "rand=np.arange(60000)\n",
    "np.random.shuffle(rand)\n",
    "train_no=rand[:50000]\n",
    "\n",
    "val_no=np.setdiff1d(rand,train_no)\n",
    "\n",
    "X_train,X_val=X[train_no,:,:],X[val_no,:,:]\n",
    "Y_train,Y_val=Y[train_no],Y[val_no]\n",
    "val_no=np.setdiff1d(rand,train_no)\n",
    "\n",
    "# display some of the X_train data as images\n",
    "for i in range(9):\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    pyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "    pyplot.show()\n",
    "\n",
    "# 3 layers: 784 input, 128 second, 10 last\n",
    "def init(x,y):\n",
    "    layer=np.random.uniform(-1.,1.,size=(x,y))/np.sqrt(x*y)\n",
    "    return layer.astype(np.float32)\n",
    "\n",
    "np.random.seed(42)\n",
    "l1=init(28*28,128)\n",
    "l2=init(128,10)\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(np.exp(-x)+1)    \n",
    "\n",
    "# derivative of sigmoid\n",
    "def d_sigmoid(x):\n",
    "    return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "\n",
    "# softmax - normalizes a vector?\n",
    "\n",
    "# softmax\n",
    "def softmax(x):\n",
    "    exp_element=np.exp(x-x.max())\n",
    "    return exp_element/np.sum(exp_element,axis=0)\n",
    "\n",
    "# derivative of softmax\n",
    "def d_softmax(x):\n",
    "    exp_element=np.exp(x-x.max())\n",
    "    return exp_element/np.sum(exp_element,axis=0)*(1-exp_element/np.sum(exp_element,axis=0))\n",
    "\n",
    "# forward backward pass\n",
    "def forward_backward_pass(x,y):\n",
    "    # convert y into vector having 1 for “correct” digit and 0 for the rest\n",
    "    targets = np.zeros((len(y),10), np.float32)\n",
    "    targets[range(targets.shape[0]),y] = 1\n",
    "    \n",
    "    # multiply input matrix with weights\n",
    "    # pass through respective activation Fns\n",
    "    x_l1=x.dot(l1)\n",
    "    x_sigmoid=sigmoid(x_l1)\n",
    "    x_l2=x_sigmoid.dot(l2)\n",
    "    out=softmax(x_l2)    # product of the NN\n",
    "    \n",
    "    # calculate errors and derivatives\n",
    "    error=2*(out-targets)/out.shape[0]*d_softmax(x_l2)\n",
    "    update_l2=x_sigmoid.T@error\n",
    "    \n",
    "    error=((l2).dot(error.T)).T*d_sigmoid(x_l1)\n",
    "    update_l1=x.T@error\n",
    "    \n",
    "    return out,update_l1,update_l2 \n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "epochs=10000\n",
    "lr=0.001\n",
    "batch=128\n",
    "\n",
    "losses,accuracies,val_accuracies=[],[],[]\n",
    "\n",
    "for i in range(epochs):\n",
    "    # 128 elements randomly chosen from 0 to 50000\n",
    "    sample=np.random.randint(0,X_train.shape[0],size=(batch))\n",
    "    # get elements from X_train and Y_train having corresponding indices\n",
    "    x=X_train[sample].reshape((-1,28*28))\n",
    "    y=Y_train[sample]\n",
    " \n",
    "    # put x and y through forward_backward pass Fn and store vals\n",
    "    out,update_l1,update_l2=forward_backward_pass(x,y)\n",
    "    \n",
    "    # pick category, calculate accuracy of batch  \n",
    "    category=np.argmax(out,axis=1)\n",
    "    accuracy=(category==y).mean()\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    # calculate loss using MSE loss\n",
    "    loss=((category-y)**2).mean()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    # update weights\n",
    "    l1=l1-lr*update_l1\n",
    "    l2=l2-lr*update_l2\n",
    "    \n",
    "    # test on validation set for accuracy\n",
    "    if(i%20==0):    \n",
    "        X_val=X_val.reshape((-1,28*28))\n",
    "        val_out=np.argmax(softmax(sigmoid(X_val.dot(l1)).dot(l2)),axis=1)\n",
    "        val_acc=(val_out==Y_val).mean()\n",
    "        val_accuracies.append(val_acc.item())\n",
    "    if(i%500==0): print(f'For {i}th epoch: train accuracy: {accuracy:.3f} | validation accuracy:{val_acc:.3f}')\n",
    "\n",
    "# test         \n",
    "m = [[0,0,0,0,0,0,0],\n",
    "     [0,0,10,10,10,0,0],\n",
    "     [0,0,0,0,10,0,0],\n",
    "     [0,0,0,0,10,0,0],\n",
    "     [0,0,0,0,10,0,0],\n",
    "     [0,0,0,0,10,0,0],\n",
    "     [0,0,0,0,0,0,0]]\n",
    "\n",
    "m = np.concatenate([np.concatenate([[x]*4 for x in y]*4) for y in m])\n",
    "m=m.reshape(1,-1)\n",
    "pyplot.imshow(m.reshape(28,28))\n",
    "x = np.argmax(sigmoid(m.dot(l1)).dot(l2),axis=1)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
